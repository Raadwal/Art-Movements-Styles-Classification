{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8O93BMLCI_SR",
        "outputId": "b1302b1d-4897-4771-fefa-af269ed659be"
      },
      "outputs": [],
      "source": [
        "!pip install deeplake[enterprise]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTmfej0aInWM"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import deeplake\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u86REDSpNaqf"
      },
      "outputs": [],
      "source": [
        "token = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpAfDFdSgvV0",
        "outputId": "1d14ea0b-1117-429b-a8ed-03e6f2266f32"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVPC5_EKJA_B",
        "outputId": "6b3d4d4b-11f6-4ce0-e90f-ba7ab4ec4dce"
      },
      "outputs": [],
      "source": [
        "train_ds = deeplake.load('hub://um_project/art-train', token=token, read_only=True)\n",
        "dev_ds = deeplake.load('hub://um_project/art-dev', token=token, read_only=True)\n",
        "val_ds = deeplake.load('hub://um_project/art-val', token=token, read_only=True)\n",
        "test_ds = deeplake.load('hub://um_project/art-test', token=token, read_only=True)\n",
        "shap_ds = deeplake.load('hub://um_project/art-shap', token=token, read_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHzstNa7JI-F",
        "outputId": "900e75a5-f5cf-4ae6-a7db-0ac4f70fd57d"
      },
      "outputs": [],
      "source": [
        "print(f'Size of train dataset: {len(train_ds)}')\n",
        "print(f'Size of dev dataset: {len(dev_ds)}')\n",
        "print(f'Size of validation dataset: {len(val_ds)}')\n",
        "print(f'Size of test dataset: {len(test_ds)}')\n",
        "print(f'Size of shap dataset: {len(shap_ds)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gll9FKPuJK1A",
        "outputId": "beeefcfc-fbf7-4ae9-c956-07165d2ffb4d"
      },
      "outputs": [],
      "source": [
        "classes_labels = train_ds.labels.info.class_names\n",
        "num_classes = len(classes_labels)\n",
        "print(f'Number of classes: {num_classes}')\n",
        "for i, label in enumerate(classes_labels):\n",
        "  print(f'{i}. {label}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZnQReYTFOx-m",
        "outputId": "a7defca2-3fe8-48f2-c932-adb2c898c7b2"
      },
      "outputs": [],
      "source": [
        "def plot_class_distribution(ax, class_counts, class_labels, dataset_name):\n",
        "    ax.bar(np.arange(len(class_labels)), class_counts, tick_label=class_labels)\n",
        "    ax.set_xlabel('Class', weight='bold')\n",
        "    ax.set_xticklabels(class_labels, rotation='vertical')\n",
        "    ax.set_ylabel('Number of Instances', weight='bold')\n",
        "    ax.set_title(f'Frequency per Class ({dataset_name})', weight='bold')\n",
        "\n",
        "class_train_count = np.bincount(np.concatenate(train_ds.labels.numpy(aslist = True), axis=0))\n",
        "class_dev_count = np.bincount(np.concatenate(dev_ds.labels.numpy(aslist = True), axis=0))\n",
        "class_val_count = np.bincount(np.concatenate(val_ds.labels.numpy(aslist = True), axis=0))\n",
        "class_test_count = np.bincount(np.concatenate(test_ds.labels.numpy(aslist = True), axis=0))\n",
        "\n",
        "fig, axs = plt.subplots(2, 2, figsize=(12, 12), constrained_layout=True)\n",
        "\n",
        "plot_class_distribution(axs[0, 0], class_train_count, classes_labels, \"Train\")\n",
        "plot_class_distribution(axs[0, 1], class_dev_count, classes_labels, \"Dev\")\n",
        "plot_class_distribution(axs[1, 0], class_val_count, classes_labels, \"Val\")\n",
        "plot_class_distribution(axs[1, 1], class_test_count, classes_labels, \"Test\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O6NxqpqAc4QP",
        "outputId": "bfcefc02-a9ff-48a8-d8e7-862a01e05d68"
      },
      "outputs": [],
      "source": [
        "# Initialize a dictionary to store images for each class\n",
        "class_images = {label: [] for label in classes_labels}\n",
        "\n",
        "# Iterate through the dataset and store 7 images for each class\n",
        "for i, sample in enumerate(train_ds):\n",
        "    label = sample['labels'].data()['text'][0]  # Access the first element of the list\n",
        "    if len(class_images[label]) < 7:\n",
        "        image_array = sample['images'].data()['value']\n",
        "        class_images[label].append(image_array)\n",
        "        \n",
        "    # Stop iterating if we already have 7 images for each class\n",
        "    if all(len(images) == 7 for images in class_images.values()):\n",
        "        break\n",
        "\n",
        "\n",
        "# Create a grid of subplots and display the images\n",
        "num_classes = len(classes_labels)\n",
        "num_images_per_class = 7\n",
        "fig = plt.figure(figsize=(28, 56))\n",
        "\n",
        "for i, class_label in enumerate(classes_labels):\n",
        "    for j, image_array in enumerate(class_images[class_label]):\n",
        "        ax = fig.add_subplot(num_classes, num_images_per_class, i * num_images_per_class + j + 1)\n",
        "        ax.imshow(image_array)\n",
        "        ax.axis('off')\n",
        "\n",
        "        # Set the class name above the first image in each row\n",
        "        if j == int(num_images_per_class / 2):\n",
        "            ax.set_title(class_label, fontsize=32, ha='center', va='center', weight='bold')\n",
        "\n",
        "plt.tight_layout(pad=3.0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyaZLuWjKOG0"
      },
      "outputs": [],
      "source": [
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # ImageNet statistics\n",
        "])\n",
        "\n",
        "def one_hot_encode(label, num_classes):\n",
        "    one_hot = torch.zeros(num_classes)\n",
        "    one_hot[label] = 1\n",
        "    return one_hot\n",
        "\n",
        "batch_size = 64\n",
        "num_workers = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Odp3bnmkiYAL"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(dataset, batch_size, num_classes, image_transform, shuffle=True, num_workers=0):\n",
        "    return dataset.pytorch(\n",
        "        num_workers=num_workers,\n",
        "        batch_size=batch_size,\n",
        "        transform={\n",
        "            'images': image_transform,\n",
        "            'labels': lambda label: one_hot_encode(label, num_classes),\n",
        "        },\n",
        "        shuffle=shuffle,\n",
        "        decode_method={'images': 'pil'}\n",
        "    )\n",
        "\n",
        "# Create data loaders for different datasets\n",
        "train_loader = create_data_loader(train_ds, batch_size, num_classes, image_transform)\n",
        "dev_loader = create_data_loader(dev_ds, batch_size, num_classes, image_transform)\n",
        "val_loader = create_data_loader(val_ds, batch_size, num_classes, image_transform)\n",
        "test_loader = create_data_loader(test_ds, batch_size, num_classes, image_transform)\n",
        "shap_loader = create_data_loader(shap_ds, 13, num_classes, image_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gudY_y9gucsb"
      },
      "outputs": [],
      "source": [
        "def save_model(model, optimizer, epoch, save_path, model_name):\n",
        "  # Create the save directory if it doesn't exist\n",
        "  if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "  # Create the full path for the saved model\n",
        "  model_file = os.path.join(save_path, f\"{model_name}_epoch_{epoch}.pth\")\n",
        "\n",
        "  # Save the model and optimizer state_dicts\n",
        "  torch.save({\n",
        "    'epoch': epoch,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "  }, model_file)\n",
        "\n",
        "  print(f\"Model saved: {model_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tQY7um_ud9z"
      },
      "outputs": [],
      "source": [
        "def load_model(model, optimizer, load_path, device):\n",
        "  # Load the saved model and optimizer state_dicts\n",
        "  checkpoint = torch.load(load_path)\n",
        "\n",
        "  # Load the model and optimizer state_dicts into the model and optimizer objects\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "  # Move the model to the appropriate device (GPU or CPU)\n",
        "  model.to(device)\n",
        "\n",
        "  # Set the starting epoch for the model\n",
        "  start_epoch = checkpoint['epoch']\n",
        "\n",
        "  print(f\"Model loaded: {load_path}, starting from epoch {start_epoch}\")\n",
        "\n",
        "# Usage example:\n",
        "#load_path = \"/content/drive/MyDrive/SSN_Projekt/Saved_Models/MultiLabelCNN_epoch_1.pth\"\n",
        "#load_model(model, optimizer, load_path, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EK8GVYuCXs4K"
      },
      "outputs": [],
      "source": [
        "def train_validate(model, train_loader, val_loader, criterion, optimizer, device, num_epochs, patience):\n",
        "    \n",
        "    save_path = \"/content/drive/MyDrive/UM_Projekt/Saved_Models\" \n",
        "    model_name = \"Net\"\n",
        "\n",
        "    best_val_accuracy = 0.0\n",
        "    best_model = None\n",
        "    counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            inputs, labels = data['images'].to(device), data['labels'].to(device)\n",
        "\n",
        "            # Convert one-hot encoded labels to class indices\n",
        "            labels = torch.argmax(labels, dim=1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_epoch_loss = running_loss / (i + 1)\n",
        "        train_epoch_accuracy = correct / total * 100\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(val_loader, 0):\n",
        "                inputs, labels = data['images'].to(device), data['labels'].to(device)\n",
        "\n",
        "                # Convert one-hot encoded labels to class indices\n",
        "                labels = torch.argmax(labels, dim=1)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_epoch_loss = running_loss / (i + 1)\n",
        "        val_epoch_accuracy = correct / total * 100\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {train_epoch_loss:.4f}, Training Accuracy: {train_epoch_accuracy:.2f}%, Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_epoch_accuracy:.2f}%\")\n",
        "\n",
        "        # Save the model after each epoch\n",
        "        save_model(model, optimizer, epoch + 1, save_path, model_name)\n",
        "\n",
        "        # Save the best model and implement early stopping\n",
        "        if val_epoch_accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = val_epoch_accuracy\n",
        "            best_model = copy.deepcopy(model.state_dict())\n",
        "            counter = 0\n",
        "\n",
        "            save_model(model, optimizer, epoch + 1, save_path, f\"{model_name}_Best\")\n",
        "        else:\n",
        "            counter += 1\n",
        "            if counter >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch + 1}. Best Validation Accuracy: {best_val_accuracy:.2f}%\")\n",
        "                break\n",
        "\n",
        "    # Load the best model\n",
        "    model.load_state_dict(best_model)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6zOYpEiwjso"
      },
      "outputs": [],
      "source": [
        "def test_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(test_loader, 0):\n",
        "            inputs, labels = data['images'].to(device), data['labels'].to(device)\n",
        "\n",
        "            # Convert one-hot encoded labels to class indices\n",
        "            labels = torch.argmax(labels, dim=1)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_accuracy = correct / total * 100\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "    return test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPUKQwmT7XSp",
        "outputId": "2cfda0a5-48eb-4cbf-d9c0-5f7978a00b08"
      },
      "outputs": [],
      "source": [
        "num_classes = 13\n",
        "flatten_out = 325\n",
        "\n",
        "class SubNet(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride, padding, pool_kernel, pool_stride, dropout_rate):\n",
        "    super(SubNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "    self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "    self.relu1 = nn.LeakyReLU(inplace=True)\n",
        "    self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "    self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "    self.relu2 = nn.LeakyReLU(inplace=True)\n",
        "    self.max_pool = nn.MaxPool2d(kernel_size=pool_kernel, stride=pool_stride)\n",
        "    self.drop = nn.Dropout(dropout_rate)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.conv1(x)\n",
        "      x = self.bn1(x)\n",
        "      x = self.relu1(x)\n",
        "      x = self.conv2(x)\n",
        "      x = self.bn2(x)\n",
        "      x = self.relu2(x)\n",
        "      x = self.max_pool(x)\n",
        "      x = self.drop(x)\n",
        "      return x\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.block0 = SubNet(3, 16, 3, 1, 1, 2, 2, 0.35)\n",
        "    self.block1 = SubNet(16, 32, 3, 1, 1, 2, 2, 0.35)  \n",
        "    self.block2 = SubNet(32, 64, 3, 1, 1, 2, 2, 0.35) \n",
        "    self.block3 = SubNet(64, 128, 3, 1, 1, 2, 2, 0.35) \n",
        "    self.block4 = SubNet(128, 256, 3, 1, 1, 2, 2, 0.35) \n",
        "    self.block5 = SubNet(256, 512, 3, 1, 1, 2, 2, 0.35)\n",
        "    self.block6 = SubNet(512, 512, 3, 1, 1, 2, 2, 0.35)\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc = nn.Linear(512, 13)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.block0(x)\n",
        "    x = self.block1(x)\n",
        "    x = self.block2(x)\n",
        "    x = self.block3(x) \n",
        "    x = self.block4(x) \n",
        "    x = self.block5(x)\n",
        "    x = self.block6(x)\n",
        "    x = self.avg_pool(x)\n",
        "    x = x.view(x.shape[0], -1) # flatten the tensor\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Model is curretly running on: {device}\")\n",
        "model = Net().to(device=device)\n",
        "\n",
        "# Set the loss function and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URVAhOrBkIh0",
        "outputId": "fa1900dc-a424-4a1b-fa96-4307f45e6617"
      },
      "outputs": [],
      "source": [
        "# Set the number of epochs and patience\n",
        "num_epochs = 24\n",
        "patience = 5\n",
        "\n",
        "# Train and validate the model with early stopping\n",
        "best_model = train_validate(model, train_loader, val_loader, criterion, optimizer, device, num_epochs, patience)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9F3PRnhFwwoS",
        "outputId": "fff87379-3da8-46ee-8fbf-17ee59a1c712"
      },
      "outputs": [],
      "source": [
        "save_path = \"/content/drive/MyDrive/UM_Projekt/Saved_Models\" \n",
        "model_name = \"Net\"\n",
        "best_epoch = 24\n",
        "\n",
        "best_model_path = os.path.join(save_path, f\"{model_name}_Best_epoch_{best_epoch}.pth\")\n",
        "load_model(model, optimizer, best_model_path, device)\n",
        "\n",
        "test_accuracy = test_model(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4d0iKkv97GP"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "# iterate over test data\n",
        "for inputs, labels in test_loader:\n",
        "        # Feed Network\n",
        "        output = model(inputs.to(device)) \n",
        "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
        "        # Save Prediction\n",
        "        y_pred.extend(output) \n",
        "        \n",
        "        #reverse one-hot encoding\n",
        "        labels = torch.argmax(labels, dim=1)\n",
        "        #make labels a numpy array\n",
        "        labels = labels.data.cpu().numpy()\n",
        "        # Save Truth\n",
        "        y_true.extend(labels) \n",
        "\n",
        "# Build confusion matrix\n",
        "cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes_labels],\n",
        "                     columns = [i for i in classes_labels])\n",
        "plt.figure(figsize = (12,7))\n",
        "sn.heatmap(df_cm, annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HjZ4qqYyuBr"
      },
      "outputs": [],
      "source": [
        "!pip install shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kH-tYFD-zHx"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "\n",
        "batch = next(iter(shap_loader))\n",
        "images, _ = batch\n",
        "\n",
        "batch_background = next(iter(test_loader))\n",
        "images_background, _ = batch_background"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbWGE6fhCudN"
      },
      "outputs": [],
      "source": [
        "background = images_background[:50].to(device)\n",
        "\n",
        "e = shap.DeepExplainer(model, background)\n",
        "\n",
        "shap_images = images[:13].to(device)\n",
        "shap_values = e.shap_values(shap_images)\n",
        "\n",
        "shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]\n",
        "test_numpy = np.swapaxes(np.swapaxes(shap_images.cpu().numpy(), 1, -1), 1, 2)\n",
        "\n",
        "def normalize_data(data):\n",
        "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
        "\n",
        "test_numpy = normalize_data(test_numpy)\n",
        "\n",
        "shap.image_plot(shap_numpy, test_numpy, true_labels=shap_ds.labels.info.class_names)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
