{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8O93BMLCI_SR",
        "outputId": "50d7d404-b4a8-4324-c653-634b5373f2a2"
      },
      "outputs": [],
      "source": [
        "!pip install deeplake[enterprise]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTmfej0aInWM"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import deeplake\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u86REDSpNaqf"
      },
      "outputs": [],
      "source": [
        "token = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpAfDFdSgvV0",
        "outputId": "bd0de157-7fa6-41e1-fb61-4358e581bec1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVPC5_EKJA_B",
        "outputId": "e97c18b8-0789-4747-ea73-e1cf834188e9"
      },
      "outputs": [],
      "source": [
        "train_ds = deeplake.load('hub://um_project/art-train', token=token, read_only=True)\n",
        "dev_ds = deeplake.load('hub://um_project/art-dev', token=token, read_only=True)\n",
        "val_ds = deeplake.load('hub://um_project/art-val', token=token, read_only=True)\n",
        "test_ds = deeplake.load('hub://um_project/art-test', token=token, read_only=True)\n",
        "shap_ds = deeplake.load('hub://um_project/art-shap', token=token, read_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHzstNa7JI-F",
        "outputId": "215e9dc7-d9ff-4450-96d3-6ebe9f587660"
      },
      "outputs": [],
      "source": [
        "print(f'Size of train dataset: {len(train_ds)}')\n",
        "print(f'Size of dev dataset: {len(dev_ds)}')\n",
        "print(f'Size of validation dataset: {len(val_ds)}')\n",
        "print(f'Size of test dataset: {len(test_ds)}')\n",
        "print(f'Size of shap dataset: {len(shap_ds)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gll9FKPuJK1A",
        "outputId": "df13cbf2-04a2-4a92-867f-921fbda8a7c3"
      },
      "outputs": [],
      "source": [
        "classes_labels = train_ds.labels.info.class_names\n",
        "num_classes = len(classes_labels)\n",
        "print(f'Number of classes: {num_classes}')\n",
        "for i, label in enumerate(classes_labels):\n",
        "  print(f'{i}. {label}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZnQReYTFOx-m",
        "outputId": "a7dac1b8-89e6-4039-9dfc-d551c563dd72"
      },
      "outputs": [],
      "source": [
        "def plot_class_distribution(ax, class_counts, class_labels, dataset_name):\n",
        "    ax.bar(np.arange(len(class_labels)), class_counts, tick_label=class_labels)\n",
        "    ax.set_xlabel('Class', weight='bold')\n",
        "    ax.set_xticklabels(class_labels, rotation='vertical')\n",
        "    ax.set_ylabel('Number of Instances', weight='bold')\n",
        "    ax.set_title(f'Frequency per Class ({dataset_name})', weight='bold')\n",
        "\n",
        "class_train_count = np.bincount(np.concatenate(train_ds.labels.numpy(aslist = True), axis=0))\n",
        "class_dev_count = np.bincount(np.concatenate(dev_ds.labels.numpy(aslist = True), axis=0))\n",
        "class_val_count = np.bincount(np.concatenate(val_ds.labels.numpy(aslist = True), axis=0))\n",
        "class_test_count = np.bincount(np.concatenate(test_ds.labels.numpy(aslist = True), axis=0))\n",
        "\n",
        "fig, axs = plt.subplots(2, 2, figsize=(12, 12), constrained_layout=True)\n",
        "\n",
        "plot_class_distribution(axs[0, 0], class_train_count, classes_labels, \"Train\")\n",
        "plot_class_distribution(axs[0, 1], class_dev_count, classes_labels, \"Dev\")\n",
        "plot_class_distribution(axs[1, 0], class_val_count, classes_labels, \"Val\")\n",
        "plot_class_distribution(axs[1, 1], class_test_count, classes_labels, \"Test\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O6NxqpqAc4QP",
        "outputId": "91e1d4bd-dd75-466a-b3f9-d3ce9abe86dd"
      },
      "outputs": [],
      "source": [
        "# Initialize a dictionary to store images for each class\n",
        "class_images = {label: [] for label in classes_labels}\n",
        "\n",
        "# Iterate through the dataset and store 7 images for each class\n",
        "for i, sample in enumerate(train_ds):\n",
        "    label = sample['labels'].data()['text'][0]  # Access the first element of the list\n",
        "    if len(class_images[label]) < 7:\n",
        "        image_array = sample['images'].data()['value']\n",
        "        class_images[label].append(image_array)\n",
        "\n",
        "    # Stop iterating if we already have 7 images for each class\n",
        "    if all(len(images) == 7 for images in class_images.values()):\n",
        "        break\n",
        "\n",
        "\n",
        "# Create a grid of subplots and display the images\n",
        "num_classes = len(classes_labels)\n",
        "num_images_per_class = 7\n",
        "fig = plt.figure(figsize=(28, 56))\n",
        "\n",
        "for i, class_label in enumerate(classes_labels):\n",
        "    for j, image_array in enumerate(class_images[class_label]):\n",
        "        ax = fig.add_subplot(num_classes, num_images_per_class, i * num_images_per_class + j + 1)\n",
        "        ax.imshow(image_array)\n",
        "        ax.axis('off')\n",
        "\n",
        "        # Set the class name above the first image in each row\n",
        "        if j == int(num_images_per_class / 2):\n",
        "            ax.set_title(class_label, fontsize=32, ha='center', va='center', weight='bold')\n",
        "\n",
        "plt.tight_layout(pad=3.0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyaZLuWjKOG0"
      },
      "outputs": [],
      "source": [
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # ImageNet statistics\n",
        "])\n",
        "\n",
        "def one_hot_encode(label, num_classes):\n",
        "    one_hot = torch.zeros(num_classes)\n",
        "    one_hot[label] = 1\n",
        "    return one_hot\n",
        "\n",
        "batch_size = 64\n",
        "num_workers = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Odp3bnmkiYAL"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(dataset, batch_size, num_classes, image_transform, shuffle=True, num_workers=0):\n",
        "    return dataset.pytorch(\n",
        "        num_workers=num_workers,\n",
        "        batch_size=batch_size,\n",
        "        transform={\n",
        "            'images': image_transform,\n",
        "            'labels': lambda label: one_hot_encode(label, num_classes),\n",
        "        },\n",
        "        shuffle=shuffle,\n",
        "        decode_method={'images': 'pil'}\n",
        "    )\n",
        "\n",
        "# Create data loaders for different datasets\n",
        "train_loader = create_data_loader(train_ds, batch_size, num_classes, image_transform)\n",
        "dev_loader = create_data_loader(dev_ds, batch_size, num_classes, image_transform)\n",
        "val_loader = create_data_loader(val_ds, batch_size, num_classes, image_transform)\n",
        "test_loader = create_data_loader(test_ds, batch_size, num_classes, image_transform)\n",
        "shap_loader = create_data_loader(shap_ds, 13, num_classes, image_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gudY_y9gucsb"
      },
      "outputs": [],
      "source": [
        "def save_model(model, optimizer, epoch, save_path, model_name):\n",
        "  # Create the save directory if it doesn't exist\n",
        "  if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "  # Create the full path for the saved model\n",
        "  model_file = os.path.join(save_path, f\"{model_name}_epoch_{epoch}.pth\")\n",
        "\n",
        "  # Save the model and optimizer state_dicts\n",
        "  torch.save({\n",
        "    'epoch': epoch,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "  }, model_file)\n",
        "\n",
        "  print(f\"Model saved: {model_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tQY7um_ud9z"
      },
      "outputs": [],
      "source": [
        "def load_model(model, optimizer, load_path, device):\n",
        "  # Load the saved model and optimizer state_dicts\n",
        "  checkpoint = torch.load(load_path)\n",
        "\n",
        "  # Load the model and optimizer state_dicts into the model and optimizer objects\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "  # Move the model to the appropriate device (GPU or CPU)\n",
        "  model.to(device)\n",
        "\n",
        "  # Set the starting epoch for the model\n",
        "  start_epoch = checkpoint['epoch']\n",
        "\n",
        "  print(f\"Model loaded: {load_path}, starting from epoch {start_epoch}\")\n",
        "\n",
        "# Usage example:\n",
        "#load_path = \"/content/drive/MyDrive/SSN_Projekt/Saved_Models/MultiLabelCNN_epoch_1.pth\"\n",
        "#load_model(model, optimizer, load_path, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EK8GVYuCXs4K"
      },
      "outputs": [],
      "source": [
        "def train_validate(model, train_loader, val_loader, criterion, optimizer, device, num_epochs, patience):\n",
        "\n",
        "    save_path = \"/content/drive/MyDrive/UM_Projekt/Saved_Models\"\n",
        "    model_name = \"Net\"\n",
        "\n",
        "    best_val_accuracy = 0.0\n",
        "    best_model = None\n",
        "    counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            inputs, labels = data['images'].to(device), data['labels'].to(device)\n",
        "\n",
        "            # Convert one-hot encoded labels to class indices\n",
        "            labels = torch.argmax(labels, dim=1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_epoch_loss = running_loss / (i + 1)\n",
        "        train_epoch_accuracy = correct / total * 100\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(val_loader, 0):\n",
        "                inputs, labels = data['images'].to(device), data['labels'].to(device)\n",
        "\n",
        "                # Convert one-hot encoded labels to class indices\n",
        "                labels = torch.argmax(labels, dim=1)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_epoch_loss = running_loss / (i + 1)\n",
        "        val_epoch_accuracy = correct / total * 100\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {train_epoch_loss:.4f}, Training Accuracy: {train_epoch_accuracy:.2f}%, Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_epoch_accuracy:.2f}%\")\n",
        "\n",
        "        # Save the model after each epoch\n",
        "        save_model(model, optimizer, epoch + 1, save_path, model_name)\n",
        "\n",
        "        # Save the best model and implement early stopping\n",
        "        if val_epoch_accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = val_epoch_accuracy\n",
        "            best_model = copy.deepcopy(model.state_dict())\n",
        "            counter = 0\n",
        "\n",
        "            save_model(model, optimizer, epoch + 1, save_path, f\"{model_name}_Best\")\n",
        "        else:\n",
        "            counter += 1\n",
        "            if counter >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch + 1}. Best Validation Accuracy: {best_val_accuracy:.2f}%\")\n",
        "                break\n",
        "\n",
        "    # Load the best model\n",
        "    model.load_state_dict(best_model)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6zOYpEiwjso"
      },
      "outputs": [],
      "source": [
        "def test_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(test_loader, 0):\n",
        "            inputs, labels = data['images'].to(device), data['labels'].to(device)\n",
        "\n",
        "            # Convert one-hot encoded labels to class indices\n",
        "            labels = torch.argmax(labels, dim=1)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_accuracy = correct / total * 100\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "    return test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPUKQwmT7XSp",
        "outputId": "b8703d5e-95e0-4180-e34d-483d4d510637"
      },
      "outputs": [],
      "source": [
        "num_classes = 13\n",
        "flatten_out = 325\n",
        "# blocks for creating larger network\n",
        "class SubNet(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride, padding, pool_kernel, pool_stride, dropout_rate):\n",
        "    super(SubNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "    self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "    self.relu1 = nn.LeakyReLU(inplace=True)\n",
        "    self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "    self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "    self.relu2 = nn.LeakyReLU(inplace=True)\n",
        "    self.max_pool = nn.MaxPool2d(kernel_size=pool_kernel, stride=pool_stride)\n",
        "    self.drop = nn.Dropout(dropout_rate)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.conv1(x)\n",
        "      x = self.bn1(x)\n",
        "      x = self.relu1(x)\n",
        "      x = self.conv2(x)\n",
        "      x = self.bn2(x)\n",
        "      x = self.relu2(x)\n",
        "      x = self.max_pool(x)\n",
        "      x = self.drop(x)\n",
        "      return x\n",
        "\n",
        "# neural network created out of blocks\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.block0 = SubNet(3, 16, 3, 1, 1, 2, 2, 0.35)\n",
        "    self.block1 = SubNet(16, 32, 3, 1, 1, 2, 2, 0.35)\n",
        "    self.block2 = SubNet(32, 64, 3, 1, 1, 2, 2, 0.35)\n",
        "    self.block3 = SubNet(64, 128, 3, 1, 1, 2, 2, 0.35)\n",
        "    self.block4 = SubNet(128, 256, 3, 1, 1, 2, 2, 0.35)\n",
        "    self.block5 = SubNet(256, 512, 3, 1, 1, 2, 2, 0.35)\n",
        "    self.block6 = SubNet(512, 512, 3, 1, 1, 2, 2, 0.35)\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc = nn.Linear(512, 13)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.block0(x)\n",
        "    x = self.block1(x)\n",
        "    x = self.block2(x)\n",
        "    x = self.block3(x)\n",
        "    x = self.block4(x)\n",
        "    x = self.block5(x)\n",
        "    x = self.block6(x)\n",
        "    x = self.avg_pool(x)\n",
        "    x = x.view(x.shape[0], -1) # flatten the tensor\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Model is curretly running on: {device}\")\n",
        "model = Net().to(device=device)\n",
        "\n",
        "# Set the loss function and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URVAhOrBkIh0"
      },
      "outputs": [],
      "source": [
        "# Set the number of epochs and patience\n",
        "num_epochs = 6\n",
        "patience = 5\n",
        "\n",
        "# Train and validate the model with early stopping\n",
        "# best_model = train_validate(model, train_loader, val_loader, criterion, optimizer, device, num_epochs, patience)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9F3PRnhFwwoS",
        "outputId": "b21765fc-6e6c-4850-f853-6c0e87b894e9"
      },
      "outputs": [],
      "source": [
        "save_path = \"/content/drive/MyDrive/UM_Projekt/Saved_Models\"\n",
        "model_name = \"Net\"\n",
        "best_epoch = 16\n",
        "\n",
        "best_model_path = os.path.join(save_path, f\"{model_name}_Best_epoch_{best_epoch}.pth\")\n",
        "load_model(model, optimizer, best_model_path, device)\n",
        "\n",
        "test_accuracy = test_model(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "w4d0iKkv97GP",
        "outputId": "26b72a71-f334-48ce-c8c8-767c45c66fb2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "# iterate over test data\n",
        "for inputs, labels in test_loader:\n",
        "        # Feed Network\n",
        "        output = model(inputs.to(device))\n",
        "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
        "        # Save Prediction\n",
        "        y_pred.extend(output)\n",
        "\n",
        "        #reverse one-hot encoding\n",
        "        labels = torch.argmax(labels, dim=1)\n",
        "        #make labels a numpy array\n",
        "        labels = labels.data.cpu().numpy()\n",
        "        # Save Truth\n",
        "        y_true.extend(labels)\n",
        "\n",
        "# Build confusion matrix\n",
        "cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes_labels],\n",
        "                     columns = [i for i in classes_labels])\n",
        "plt.figure(figsize = (12,7))\n",
        "sn.heatmap(df_cm, annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HjZ4qqYyuBr",
        "outputId": "8baa605f-6b92-43ee-c321-8630a705155f"
      },
      "outputs": [],
      "source": [
        "!pip install shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kH-tYFD-zHx"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "\n",
        "# get images from shap dataset\n",
        "batch = next(iter(shap_loader))\n",
        "images, images_labels = batch\n",
        "shap_true_labels = []\n",
        "\n",
        "#save label assigned to every image\n",
        "for i in range(13):\n",
        "  decoded_class_number = int(np.argmax(images_labels[i]))\n",
        "  shap_true_labels.append(shap_ds.labels.info.class_names[decoded_class_number])\n",
        "# create array 13x13 with all labels copied\n",
        "all_labels_cloned = np.repeat(np.array(shap_ds.labels.info.class_names).reshape(1,13), 13, axis=0)\n",
        "\n",
        "# create background\n",
        "batch_background = next(iter(test_loader))\n",
        "images_background, _ = batch_background"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0kHc_pE-UZA"
      },
      "outputs": [],
      "source": [
        "# sorting images and labels for Confusion Matrix style shap analysis\n",
        "# temp variables for access\n",
        "unsortedLabelsArray = np.array(shap_true_labels)\n",
        "sortedLabelsArray = np.array(shap_ds.labels.info.class_names)\n",
        "temp_images = []\n",
        "temp_labels = []\n",
        "# for each image / lable\n",
        "for i in range(len(images)):\n",
        "  # get index in unsorted images and labels arrays\n",
        "  index = np.where(unsortedLabelsArray == str(sortedLabelsArray[i]))[0][0]\n",
        "  # append to sorted temp variables\n",
        "  temp_images.append(images[index])\n",
        "  temp_labels.append(unsortedLabelsArray[index])\n",
        "# assign temp to initial tensors / arrays\n",
        "images = torch.stack(temp_images)\n",
        "shap_true_labels = temp_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WbWGE6fhCudN",
        "outputId": "499c70ae-36a7-43b7-9112-32931ebca191"
      },
      "outputs": [],
      "source": [
        "# get 50 images from backgrond and init DeepExplainer\n",
        "background = images_background[:50].to(device)\n",
        "e = shap.DeepExplainer(model, background)\n",
        "\n",
        "#get 13 images and use them for explanation\n",
        "shap_images = images[:13].to(device)\n",
        "shap_values = e.shap_values(shap_images)\n",
        "\n",
        "#convert explained images and original images to numpy\n",
        "shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]\n",
        "test_numpy = np.swapaxes(np.swapaxes(shap_images.cpu().numpy(), 1, -1), 1, 2)\n",
        "\n",
        "#normalize\n",
        "def normalize_data(data):\n",
        "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
        "test_numpy = normalize_data(test_numpy)\n",
        "\n",
        "#plot grid with all images and their explanations\n",
        "shap.image_plot(shap_numpy, test_numpy, true_labels=shap_true_labels, labels=all_labels_cloned, labelpad=0.9, width=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRjzXE36VSzk",
        "outputId": "6adb56bd-7a68-47c6-9227-e002444f8258"
      },
      "outputs": [],
      "source": [
        "# get images and labels from shap dataset and make preditions on them\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(shap_loader, 0):\n",
        "        inputs, labels = data['images'].to(device), data['labels'].to(device)\n",
        "\n",
        "        # Convert one-hot encoded labels to class indices\n",
        "        labels = torch.argmax(labels, dim=1)\n",
        "\n",
        "        # predict label using the model\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "#print original labels and prediction results\n",
        "print(\"{: >20} {: >20}\".format(\"Actual:\", \"Predicted:\"))\n",
        "for i in range(13):\n",
        "  print(\"{: >20} {: >20}\".format(shap_ds.labels.info.class_names[labels[i]], shap_ds.labels.info.class_names[predicted[i]]))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
